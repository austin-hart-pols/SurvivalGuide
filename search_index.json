[["index.html", "Survival Guide: Conquering R and living through SIS 600 Preface", " Survival Guide: Conquering R and living through SIS 600 Austin Hart Dave Ohls 2021-02-23 Preface There are hundreds of R guides available online. This is the only one written specifically for students in SIS600 at American University. It introduces the basics of R for data analysis for graduate students with no prior experience in R or statistical computing more broadly. While it will not answer all of your questions about R, we hope you will find it a useful companion to lectures, assignments, and other course materials. We regularly update this guide. If you find errors, bugs, or otherwise have suggestions about how to enhance the user experience, let us know. Just send us an email at ahart@american.edu or ohls@american.edu. "],["how-to-use-this-guide.html", "Chapter 1 How to use this guide", " Chapter 1 How to use this guide This guide introduces the basics of R for data analysis for students in SIS 600: International Affairs Stats &amp; Methods at American University. While it will not answer all of your questions about R, we hope you will find it a useful companion to lecture notes and other class materials throughout the semester. "],["download-the-data.html", "1.1 Download the data", " 1.1 Download the data It is important that you follow along with the guide by replicating the code and analysis presented throughout. You will need two datasets to do this. Use the links below to download both. Then save the files to a project folder for this course. DCPS testing.RData (download DCPS data here) This data from the DC Public School System records the results of the PARCC (Partnership for Assessment of Readiness for College and Careers) Assessment from 2017-2018. This version of the data includes the school name, level, and number of students tested, as well as the percentage of students performing at or above grade level in language and math. You can find more information about the test at the DC PARCC results page. biopics.xls (download biopics data here) This is a shortened version of the data behind the story Straight Outta Compton Is The Rare Biopic Not About White Dudes. published on fivethirtyeight.com. It contains IMDB data on 177 biopics from 1915 to 2014. Variables include the sex and race of the lead actor at the center of the biopic and the year in which the film was released. "],["following-along.html", "1.2 Following along", " 1.2 Following along Hands on practice is the only way to gain competence in using R for data analysis. To We present code and output throughout the guide so that you have useful examples for reference and, most importantly, for you to practice. When you see a code chunk and output, we want you to follow along by entering the code on your computer and comparing your output to whats given in the guide. Consider a chunk like the one below: # Summarize miles per gallon (mpg) summary(mtcars$mpg) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 10.4 15.4 19.2 20.1 22.8 33.9 Throughout the text, youll find that annotation and comments follow a single # and appear in light blue: # Summarize miles per gallon (mpg) The actual R commands, below, come in a mix of black, dark blue, and other accent colors. Where possible, they are shown within a pink box. Type and execute these commands in R as you follow along with the guide. summary(mtcars$mpg) The output from the commandswhat you will see in the console window after executingfollows ##. ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 10.4 15.4 19.2 20.1 22.8 33.9 Be sure to check your output against what you find here. If your output is different, or if you get an error message, review your code for typos and errors. "],["error-messages.html", "1.3 Error messages", " 1.3 Error messages Errors are common! Like any language, R syntax, spelling, and punctuation are critical in writing code. When error messages pop up in your console: Read the error message as some are clear and intuitive. Check your code for typos, capitalization, punctuation. Beyond simple coding mistakes, weve found that students frequently encounter two types of errors in this course. 1.3.1 Function not found Consider the following code and corresponding error message: mydata %&gt;% mean(varX) ## Error in mydata %&gt;% mean(varX): could not find function &quot;%&gt;%&quot; Note the specific reference to a missing function (i.e. could not find function). It usually means you need to load a package. In this case, we forgot to load tidyverse, which defines the pipe operator, %&gt;%. 1.3.2 Object not found Another common issue is that youre asking R to search for an object, file, or dataset, that doesnt exist. Consider the following: # Load the dog dataset dog = read.csv(&#39;dogdata.csv&#39;) ## Warning in file(file, &quot;rt&quot;): cannot open file ## &#39;dogdata.csv&#39;: No such file or directory ## Error in file(file, &quot;rt&quot;): cannot open the connection The error message indicates that it cannot find the file (No such file or directory). In this case, the dogdata.csv data set isnt in your project folder. Its often the case that we downloaded a data set but forgot to move it from, e.g., the Downloads folder to our project folder. So move it, and try again. # Calculate mean weight mean(dog$weight) ## Error in mean(dog$weight): object &#39;dog&#39; not found This error message is similar to the one above. R tells you that it cannot locate the object (dataframe, variable, graph, etc) that you want to work on (in this case, an object named dog). Look to see that the object is visible in your Environment window, and either load the missing object (Oops! Forgot to open the data.) or correct the spelling (Right, its capitalized: Dog) before trying again. "],["getting-started-with-r-and-rstudio.html", "Chapter 2 Getting Started with R and RStudio", " Chapter 2 Getting Started with R and RStudio R is a language for statistical computing. Its dynamic. Its powerful. Its free! RStudio is a front end program that interfaces with R. Its sleek. It makes R much easier to use. Its also free! Both are easy to install. Just be sure to install R first. "],["installing-the-software.html", "2.1 Installing the software", " 2.1 Installing the software Start by installing R on your computer. Go to the R website and click on download R in the Getting Started section. Find a mirror site of your choice (we use Statlib at Carnegie Mellon, but do whatever you like). From there click on your operating system and follow the instructions for running the Setup Wizard. Windows users: you want the base distribution. After you complete the R installation, its time to get RStudio. Go to the RStudio site and click Download RStudio. From there, select the RStudio Desktop, Open Source License. Select the appropriate installer for your platform, and install. "],["the-rstudio-interface.html", "2.2 The RStudio Interface", " 2.2 The RStudio Interface When you open RStudio, youll see an interface like the one shown below. Its possible that the four windows highlighted in the image will be in a different order. Note that you can change the size of the windows by dragging the panes separating them. FIGURE 2.1: RStudio Interface The source pane is where youll write individual scripts: the collections of R code chunks that constitute your analysis. The console is where R evaluates the code you choose to execute. Each code chunk in the console begins with the symbol &gt;, and the output from each chunk is printed below it. For example, type 2+10/5 into the console and hit enter. 2 + 10/5 ## [1] 4 The environment pane displays the objects (dataframes, graphs, lists, etc) available. Finally, the plots/help panel displays your graphs, help files, and more. For example, load a built-in data frame and create a simple histogram. Type and execute the code below: IrisData = iris hist(IrisData$Petal.Width) Notice that the data frame IrisData is now listed in the environment pane. The histogram is displayed in the plot window. "],["code-chunks.html", "2.3 Code chunks", " 2.3 Code chunks 2.3.1 Writing and executing Open RStudio, and create a new R Script file (click the icon near the upper left that looks like a piece of paper with a green plus on it). Type the following lines into the script: x = rnorm(n = 1000, mean = 10, sd = 4) mean(x) ## [1] 10.05 Execute a command from your script by clicking within the line with your mouse (or click on the line number, or click and drag to select multiple lines at once) and clicking Run (Ctrl + Enter). You can execute lines one at a time or as a group. Try executing the lines above. Compare your output. Its probably very close but not exactly the same! No worriesthe first line creates a random normal distribution. 2.3.2 Commenting with # Its important to add comments throughout your script. These can function as section headers, or as notes to your future self/colleagues on what you were attempting to do. R treats anything after the # sign as a comment and ignores it when executing commands. For instance: # Practice executing commands x = rnorm(n = 1000, mean = 10, sd = 4) # create a new object, x mean(x) # calculate the mean of it "],["r-packages.html", "2.4 R Packages", " 2.4 R Packages Rs advanced functionality comes from the use of packagesuser-defined programs (like apps on a phone)that enable it to carry out particular tasks. We rely largely on a suite of packages called the tidyverse. 2.4.1 Installing packages To install the tidyverse (or any package), use the command install.packages('packageName') in your script or console. Be sure to include the name of the package in quotes. Note that the tidyverse will take several minutes to install: install.packages(&#39;tidyverse&#39;) Just like installing an app on your phone, you only install a package once. After it downloads and unpacks, you never have to do it again. 2.4.2 Loading packages for use You only have to install a package once, but you must load it in each R session to use it. Call the desired package using the command library(packagename). Its a good idea to start any R script by loading frequently-used packages, especially tidyverse: library(tidyverse) ## -- Attaching packages -------------- tidyverse 1.3.0 -- ## v ggplot2 3.3.3 v purrr 0.3.4 ## v tibble 3.0.6 v dplyr 1.0.4 ## v tidyr 1.1.2 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.1 ## -- Conflicts ----------------- tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() Note that you can also call a specific function without loading the entire package that defines it. For example, haven::read_dta() executes the read_dta() function from the haven package without loading the package itself. "],["setting-a-directory.html", "2.5 Setting a directory", " 2.5 Setting a directory Every data project needs a home. Your working directory is the folder on your computer from which R will load data, images, etc and to which it will save your output. Its important to designate your working directory at the beginning of any script using the setwd('filepath') command. For example: setwd(&#39;C:\\\\Users\\\\ahart\\\\Documents\\\\SIS600&#39;) This is where you should save the data sets for your project. Note the use of the double backslash, \\\\, when specifying the directory. Note also that this path only works on MY computer! Youll have to specify your own path. Dont know your path? No problem. Navigate to your project folder on your computer. Similar to the left-hand panel below, you may have the option to copy the path from a button. Alternatively, right-click on your data set, and use options like Properties or Copy path as text to get the path. FIGURE 2.2: Finding your directorys path In either case, you can copy the path and paste into setwd() in your R session. Dont forget to mind your quotes and slashes! If youre unsure about the current directory, check using the getwd() function: getwd() ## [1] &quot;C:/Users/ahart/Documents/SIS600&quot; You can verify that the correct files are there using list.files(): list.files() ## [1] &quot;biopics.xls&quot; &quot;DCPS testing.RData&quot; Note that my list includes the two companion data sets to this guide. If you dont see them after you run list.files(), confirm that you downloaded the data to your computer and move them to your project folder. "],["getting-help-with-r.html", "2.6 Getting help with R", " 2.6 Getting help with R Documentation within R is sometimes helpful, sometimes less so. To see the help file for a given command, enter help(command), or (equivalently) ?command. These will bring up a tutorial with a basic description, usage, arguments, syntax, and other notes about the command. For example, to get help with setting a working directory: help(setwd) ?setwd If that fails, ask the internet by searching Google or https://rseek.org/, a search engine dedicated specifically to results about R. "],["basics-of-r-programming.html", "Chapter 3 Basics of R Programming ", " Chapter 3 Basics of R Programming "],["thinking-like-r.html", "3.1 Thinking like R", " 3.1 Thinking like R R is built in the paradigm of Object-Oriented Programming. It uses a system of objects (which contain information) and functions that operate on objects (by manipulating them in a certain way, extracting information from or about them, calculating statistics or plotting graphs based on their data, etc). Objects are identified by names, which must start with a letter, not overwrite an already-defined object, and not include any spaces. "],["objects.html", "3.2 Objects", " 3.2 Objects Objects are created by assigning them a value using the object name, followed by an assignment operator (i.e. = or &lt;-), followed by either the information they should contain or instructions for importing information from another file. Entering information without assigning it to an object simply prints the output to the console; by assigning it a name it is possible to work with it. 1:4 # prints a sequence of integers ## [1] 1 2 3 4 MyObject = 1:4 # assigns the sequence to a new object, myObject To report the contents of an object, enter the object name on a line and execute that line. MyObject ## [1] 1 2 3 4 Objects no longer needed can be removed from the workspace using remove() In this case: remove(MyObject) "],["functions-in-r.html", "3.3 Functions in R", " 3.3 Functions in R Functions operate on objects. Call on a function by using the name of the function followed by parenthesis, within which are the arguments the function takes, i.e. SomeFunction(args). Each function has its own set of arguments that tell it what object(s) to act on and what to do with them. For example: the concatenate function c(item1,item2,...) combines a series of elements into a single (vector) object, and takes as its arguments the elements to be included. c(1,2,3,4) # combine integers ## [1] 1 2 3 4 a = 1:4 # create new objects, a and b b = 5:7 c(a,b) # combine objects ## [1] 1 2 3 4 5 6 7 "],["the-pipe-operator.html", "3.4 The Pipe Operator", " 3.4 The Pipe Operator The pipe operator %&gt;% from the tidyverse package strings together a series of functions into a single command. It will take the output from the first function and use it as the input for the second, take the output from the second as input for the third, etc. For example, creating a sequence from 0 to 100 with intervals of 2, calculating the sum of these numbers, and calculating (and printing) the square root of this sum, can be done in three ways. a = seq(0,100,2) b = sum(a) c = sqrt(b) c ## [1] 50.5 sqrt(sum(seq(0,100,2))) ## [1] 50.5 seq(0,100,2) %&gt;% # pipes the sequence forward sum() %&gt;% # take the sum of the sequence; pipe forward sqrt() # square root ## [1] 50.5 The pipe operator becomes a very useful feature as you move to performing complex, multi-step operations. It allows carrying out a series of manipulations to an object without having to create a new named object each step of the way, or getting lost in endless nesting of parentheses within a command. "],["working-with-data.html", "Chapter 4 Working with data", " Chapter 4 Working with data Typically, a dataset will take the form of a data frame (or a tibble) where each column is a vector representing a single variable and each row (i.e. each corresponding position within those vectors) represents a single observation. Each element, then, is the value a particular observation takes on for that particular variable. Note that you will need access to the DCPS testing.RData and biopics.xls data sets to follow along in this chapter. "],["importing-data.html", "4.1 Importing data", " 4.1 Importing data One of the biggest challenges for first-time R users is importing a dataset. Though the process is similar, the specific functions for loading data depend on the format of your data. Here we cover how to import the most common types of data files. 4.1.1 R data (.rdata) The file extension for a data frame saved in R is .RData. An object can be opened using the load('filename') command. Test this out by loading the DCPS testing.RData data. load(&#39;DCPS testing.RData&#39;) Note that this works only if the dataset is saved in the working directory. If not, you need to specify the complete file path in this command. 4.1.2 Delimited (.csv) files Often the datasets you work with will not be in .rdata format, or it will be more convenient to store them in another format so that you can create or work with them using other software. The simplest option is to work with Comma-Separated Values (.csv) files. To import data from a .csv file, use the read_csv('filename') function defined within tidyverse. myCSV &lt;- read_csv(&#39;csvData.csv&#39;) 4.1.3 Excel (.xls, .xlsx) files To import data from Excel (.xlsx or .xls), use the read_excel('filename') function defined in the readxl package. Note that readxl installs automatically with the tidyverse, but you have to load it separately. Practice this command by loading the biopic.xls data required for this guide. library(readxl) film &lt;- read_excel(&#39;biopics.xls&#39;) If it does not load, verify that the dataset is saved in your working directory. 4.1.4 Stata (.dta) or SPSS (.sav) files To import datafiles written in Stata (.dta) or SPSS (.sav), we rcommend using the read_dta('filename') and read_spss('filename') functions defined in the haven package. Note that haven is part of the tidyverse, but you must load it separately. library(haven) myStata &lt;- read_dta(&#39;stataData.dta&#39;) # Stata format mySPSS &lt;- read_spss(&#39;spssData.sav&#39;) # SPSS format "],["a-first-look-at-your-data.html", "4.2 A first look at your data", " 4.2 A first look at your data You can use the names() function to see a list of variables (names and column number) in your data frame. Use the head() function to preview the first rows of a data frame. To view the entire data frame, either click on the object in the Data window or use View(). names(dcps) # identify variable names ## [1] &quot;SchCode&quot; &quot;SchName&quot; &quot;SchType&quot; ## [4] &quot;NumTested&quot; &quot;ProfLang&quot; &quot;ProfMath&quot; ## [7] &quot;DataVERSION&quot; head(dcps) # see the first few rows of data ## # A tibble: 6 x 7 ## SchCode SchName SchType NumTested ProfLang ProfMath ## &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 202 Aiton ~ Elemen~ 72 5.56 15.3 ## 2 203 Amidon~ Elemen~ 147 16.3 10.1 ## 3 450 Anacos~ High 67 4.48 1.43 ## 4 452 Ballou~ High 180 2.78 0.498 ## 5 204 Bancro~ Elemen~ 213 34.3 39.9 ## 6 205 Barnar~ Elemen~ 224 38.4 39.7 ## # ... with 1 more variable: DataVERSION &lt;chr&gt; "],["referencing-variables-of-a-data-frame.html", "4.3 Referencing variables of a data frame", " 4.3 Referencing variables of a data frame A data frame (or tibble) is a two-dimensional structure in which each variable forms a column and each observation forms a row. Each element is the value that a given observation takes on for a particular variable. How do you reference or identify the variables in a data frame (e.g. to calculate the mean number of students tested, NumTested from the dcps schools data)? The $ and [[ extraction operators both pull variables from a dataframe or items from a list. Note that $ requires the variable name, whereas [[ allows you to use either the variables name (in quotes) or column number in the data frame. Do what you want. I prefer [[ for anyone in more advanced programming, but Ill typically use $ in this course. # Extract the variable (all observations) dcps$NumTested ## [1] 72 147 67 180 213 224 158 112 157 375 ## [11] 222 149 167 67 83 87 96 121 289 109 ## [21] 495 62 1423 146 117 156 109 189 212 159 ## [31] 112 77 137 112 362 310 110 160 94 91 ## [41] 178 334 290 235 354 114 156 137 115 181 ## [51] 306 111 96 193 246 132 12 129 93 153 ## [61] 143 140 212 143 105 148 258 129 66 144 ## [71] 399 133 117 79 144 213 120 288 96 170 ## [81] 20 61 121 261 135 102 113 134 121 73 ## [91] 217 211 175 409 239 126 102 374 199 180 ## [101] 173 190 23 253 172 154 152 421 # Mean on a variable (3 ways) mean(dcps$NumTested) # object$variable ## [1] 180.1 mean(dcps[[&#39;NumTested&#39;]]) # object[[&#39;variable&#39;]] ## [1] 180.1 mean(dcps[[4]]) # object[[column#]] ## [1] 180.1 "],["saving-your-work.html", "4.4 Saving your work", " 4.4 Saving your work Always save your work! Early and often! This is true both of both your scripts and your data sets. R will ask if you want to save your workspace when you close the session, and you should not. Save your script instead. 4.4.1 Saving an R script To save you .r script file in RStudio, go to File - Save (or Save As). 4.4.2 Saving a data frame To save a data frame as a .rdata data file, use the save(object,'filename') command. To save a data frame as (i.e. write it onto) a .csv file, use the write_csv(object, 'filename') command and enter the name of the object and the file name. save(myData, file = &#39;sampledata.rdata&#39;) # to save as an Rdata file write_csv(myData, file = &#39;sampledata.csv&#39;) # to write onto a .csv file As always, these actions will write the new file to your working directory. If you have not specified a working directory, or if you want to save elsewhere, specify the complete path name here. "],["descriptive-statistics.html", "Chapter 5 Descriptive statistics", " Chapter 5 Descriptive statistics How do you summarize numeric data (continuous or discrete) and present your findings? Here we cover how to analyze data over a single numeric variable, both in isolation (e.g. basic summary statistics) and across discrete categories of another variable (e.g. group mean comparison). Note that you will need the dcps data (DCPS testing.RData) to replicate the examples in this chapter. "],["describing-one-variable.html", "5.1 Describing one variable", " 5.1 Describing one variable 5.1.1 Summary statistics A useful first step in analyzing the distribution of scores on a single numeric variable is to calculate the relevant summary statistics. Use the summary() function for a quick, general overview. This returns the minimum, mean, and maximum scores, as well as the score at 1st, 2nd (median), and 3rd quartiles. summary(dcps) # for every variable in the data frame ## SchCode SchName SchType ## Min. :202 Length:108 Elementary:64 ## 1st Qu.:264 Class :character Middle :25 ## Median :318 Mode :character High :19 ## Mean :340 ## 3rd Qu.:414 ## Max. :943 ## NumTested ProfLang ProfMath ## Min. : 12 Min. : 0.0 Min. : 0.00 ## 1st Qu.: 112 1st Qu.:12.3 1st Qu.: 9.38 ## Median : 146 Median :19.1 Median :20.56 ## Mean : 180 Mean :29.7 Mean :26.96 ## 3rd Qu.: 212 3rd Qu.:40.0 3rd Qu.:36.88 ## Max. :1423 Max. :94.1 Max. :82.76 ## DataVERSION ## Length:108 ## Class :character ## Mode :character ## ## ## summary(dcps$ProfLang) # for a specific variable ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 12.3 19.1 29.7 40.0 94.1 For specific inquiries, use the summarize() function and customize your report. For example: dcps %&gt;% # start by piping in the dataset summarize( Avg = mean(ProfLang), # calculates the mean StdDev = sd(ProfLang), # standard deviation Range = max(ProfLang) - min(ProfLang) ) ## # A tibble: 1 x 3 ## Avg StdDev Range ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 29.7 24.6 94.1 5.1.2 Graphing the distribution We typically use a histogram or box plot to visualize the distribution of scores on a numeric variable. # Basic histogram hist(dcps$ProfLang) # Basic boxplot boxplot(dcps$ProfLang, horizontal = TRUE) See the chapter on data visualization to learn how to format these graphs appropriately for academic or professional settings. 5.1.3 Testing hypotheses A one-sample \\(t-\\)test (t.test()) compares the observed mean on a numeric variable to a hypothesized mean. The resulting \\(p\\)-value indicates the probability of observing the mean in your data from a population defined by the null hypothesis (mu =). For example, evaluate the argument that at least half of DC public school pupils read at or above grade level (i.e. \\(H_0:~\\mu \\geq 50\\)). t.test(dcps$ProfLang, mu = 50, alternative = &#39;less&#39;) ## ## One Sample t-test ## ## data: dcps$ProfLang ## t = -8.6, df = 107, p-value = 5e-14 ## alternative hypothesis: true mean is less than 50 ## 95 percent confidence interval: ## -Inf 33.66 ## sample estimates: ## mean of x ## 29.73 The test results suggest that it is extremely unlikely (\\(t=-8.6\\), \\(p&lt;0.001\\)) that we would observe these data if the majority of DC public school pupils read at or above grade level. We can reject the null hypothesis. "],["omitting-missing-values.html", "5.2 Omitting missing values", " 5.2 Omitting missing values If some observations have missing data (coded NA) on a given variable, summary statistic functions may yield an error. To ignore any missing values in carrying out calculations, include the argument na.rm=TRUE in the function. a = c(1,3,5,NA,7) mean(a) # Operation fails ## [1] NA mean(a, na.rm = TRUE) # Successfully calculates the mean ## [1] 4 "],["group-comparisons.html", "5.3 Group comparisons", " 5.3 Group comparisons 5.3.1 Summary statistics by group Comparing summary statistics across different groups or categories of cases requires that you identify the grouping variable (typically group_by()} before calculating the desired summary statistics. dcps %&gt;% group_by(SchType) %&gt;% # identify grouping variable summarize( Avg = mean(ProfMath), # apply functions to each group StDev = sd(ProfMath) ) ## # A tibble: 3 x 3 ## SchType Avg StDev ## * &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Elementary 34.0 23.7 ## 2 Middle 19.6 17.6 ## 3 High 12.9 22.5 5.3.2 Visualize group differences One good way of exploring these relationships graphically is to use a boxplot. Note that the syntax is to identify the outcome before the ~ and the grouping variable after (boxplot(OutcomeVar ~ GroupVar, Data)): boxplot(ProfMath ~ SchType, data = dcps) 5.3.3 Testing hypotheses You can test hypotheses about the relationship between a nominal exposure variable (GroupingVar) and a numeric outcome (OutcomeVar) using either the \\(t-\\) or \\(F-\\) test. Use t.test(OutcomeVar ~ GroupVar, Data) to compare the mean outcome across exactly two groups (i.e. when GroupVar is binary). Use aov(OutcomeVar ~ GroupVar, Data) when GroupVar identifies more than two categories. Note that you need to use summary() to view the full aov() estimates. Evaluate the argument that large schools (i.e. where more than 200 students took the test) have a significantly different level of math proficiency than small schools. # t-test (two-group test of equivalence) t.test(ProfMath ~ (NumTested &gt; 200), data = dcps) ## ## Welch Two Sample t-test ## ## data: ProfMath by NumTested &gt; 200 ## t = -1.1, df = 48, p-value = 0.3 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -16.67 4.56 ## sample estimates: ## mean in group FALSE mean in group TRUE ## 25.33 31.39 While there is a mean difference in math proficiency (31 vs 25), the difference is not statistically significant (\\(p=0.257\\)). Next consider the possibility that math proficiency differs systematically across type of school. Because SchType has more than two values (Elementary, Middle, and High), we use the \\(F-\\)test. # F-test (multigroup test of equivalence) ftest = aov(ProfMath ~ SchType, data = dcps) summary(ftest) # view the results of the F-test ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## SchType 2 8244 4122 8.32 0.00044 *** ## Residuals 105 51992 495 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Here the results indicate a significant difference in math proficiency by type of school (\\(F_{2,105}=8.35\\), \\(p&lt;0.001\\)). "],["frequency-and-cross-tabulation.html", "Chapter 6 Frequency and cross tabulation", " Chapter 6 Frequency and cross tabulation Nominal data require a different approach. Rather than summary statistics, the relevant information here is the frequency with which each value or category appears in the data. Here we cover how to analyze data for a single nominal variable (e.g. frequency tables and bar charts) and how to evaluate relationships between nominal variables (cross-tabulation). Note that you will need the film data (biopics.xls) to replicate the examples in this chapter. "],["describing-one-variable-1.html", "6.1 Describing one variable", " 6.1 Describing one variable 6.1.1 Frequency tables The count() function in tidyverse creates a tibble with each value of the variable and the count of observations within. # Frequency table Tab = film %&gt;% # the dataset count(SubjectSex) # the variable to count Tab ## # A tibble: 2 x 2 ## SubjectSex n ## * &lt;chr&gt; &lt;int&gt; ## 1 Female 177 ## 2 Male 584 Calculating the the percent of total cases in each category (relative frequency) requires an extra line of code (mutate(Percent = 100 * n/sum(n))). # Relative frequency Tab = Tab %&gt;% mutate(Percent = 100 * n/sum(n)) Tab ## # A tibble: 2 x 3 ## SubjectSex n Percent ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Female 177 23.3 ## 2 Male 584 76.7 6.1.2 Bar charts Use a basic barplot() to display the results saved into these objects (rawTab). Note the notation here is barplot(count ~ category, data): barplot(n ~ SubjectSex, Tab) barplot(Percent ~ SubjectSex, Tab) "],["cross-tabulation.html", "6.2 Cross-tabulation", " 6.2 Cross-tabulation There is a three-step process for presenting and evaluating the association between two nominal variables. The first step is to create a basic cross-tabulation of the joint frequency using the count() function. Here we consider the possibility that the representation of female subjects in biopics (SubjectSex) has changed over time (Period). # Raw cross-tabulation xtab = film %&gt;% count(SubjectSex,Period) %&gt;% # (OutcomeVar,ExposureVar) na.omit() %&gt;% # drop NA categories # now organize results into a 2-way table pivot_wider( names_from = Period, # MUST be the ExposureVar values_from = n, values_fill = 0 ) xtab ## # A tibble: 2 x 4 ## SubjectSex `1915--1965` `1965--1999` `2000--2014` ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Female 44 59 74 ## 2 Male 132 203 249 Second, use chisq.test() to conduct a \\(\\chi^2\\) test of independence. Specify the contingency table created above and add [-1] to exclude the first column (category names) from the calculation/ chisq.test(xtab[-1]) ## ## Pearson&#39;s Chi-squared test ## ## data: xtab[-1] ## X-squared = 0.4, df = 2, p-value = 0.8 Based on these results, the given sex of biopic subjects is independent of (ie does not differ systematically across) time period. The relationship is not statistically significant (\\(\\chi^2(2,N=761)=0.40\\), \\(p=0.81\\)). Finally, to present the results of a cross-tabulation, convert the raw frequencies in your table to percentages (within categories of the the exposure variable). Start by calling the raw tabulation from above. # Relative freq for presentations xtab %&gt;% # add a row total mutate(Total = rowSums(.[-1])) %&gt;% # convert to percentage mutate_at(-1, ~ round(100 * ./sum(.), digits=1)) ## # A tibble: 2 x 5 ## SubjectSex `1915--1965` `1965--1999` `2000--2014` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Female 25 22.5 22.9 ## 2 Male 75 77.5 77.1 ## # ... with 1 more variable: Total &lt;dbl&gt; Copy and paste the table into your document. Then format appropriately (e.g. category labels) for final presentation. "],["regression-analysis.html", "Chapter 7 Regression analysis", " Chapter 7 Regression analysis Regression is a powerful tool for estimating the relationship between an outcome (or dependent) variable and one or more exposure (or independent) variables. Here we cover how to estimate and present regression models in R. Note that you will need the dcps (\"DCPS testing.RData\") dataset to replicate the output in this chapter. "],["correlation.html", "7.1 Correlation", " 7.1 Correlation To calculate the correlation coefficient (r) between two numeric variables, use the cor.test() function and specify the model as ~ Var1 + Var2. This structure is unusual in that both variables follow the ~, and the + separates the two. cor.test(~ ProfMath + ProfLang, dcps) ## ## Pearson&#39;s product-moment correlation ## ## data: ProfMath and ProfLang ## t = 22, df = 106, p-value &lt;2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.8691 0.9369 ## sample estimates: ## cor ## 0.9088 Perhaps not surprisingly, the results suggest that math and language proficiency are positively and strongly correlated (\\(r=0.91\\)). It is unlikely we observe this association by chance alone (\\(t=22.4\\), \\(p&lt;0.001\\)). Use a scatterplot (plot()) to visualize this bivariate association. Be sure to specify the formula as OutcomeVar ~ ExposureVar: plot(ProfMath ~ ProfLang, dcps) "],["ols-regression.html", "7.2 OLS regression", " 7.2 OLS regression Estimating a regression model using OLS is simple in R. Using the lm() function will estimate a model with one or more independent variables. Simply specify the formula using the syntax: Y ~ X1 + X2. # Bivariate (unconditional) estimate Model1 &lt;- lm(ProfMath ~ ProfLang, data = dcps) # Multivariate (conditional) estimate Model2 &lt;- lm(ProfMath ~ ProfLang + NumTested, data = dcps) To view the coefficient estimates and evaluate hypotheses about the relationship, apply the summary() function to the model object. summary(Model1) ## ## Call: ## lm(formula = ProfMath ~ ProfLang, data = dcps) ## ## Residuals: ## Min 1Q Median 3Q Max ## -38.23 -5.15 -0.91 7.17 26.92 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.9096 1.5049 0.6 0.55 ## ProfLang 0.8761 0.0391 22.4 &lt;2e-16 *** ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.94 on 106 degrees of freedom ## Multiple R-squared: 0.826, Adjusted R-squared: 0.824 ## F-statistic: 503 on 1 and 106 DF, p-value: &lt;2e-16 summary(Model2) ## ## Call: ## lm(formula = ProfMath ~ ProfLang + NumTested, data = dcps) ## ## Residuals: ## Min 1Q Median 3Q Max ## -39.33 -5.41 -0.80 6.98 26.43 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.2109 1.7146 1.29 0.20 ## ProfLang 0.8943 0.0405 22.06 &lt;2e-16 *** ## NumTested -0.0102 0.0066 -1.55 0.12 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.88 on 105 degrees of freedom ## Multiple R-squared: 0.83, Adjusted R-squared: 0.827 ## F-statistic: 256 on 2 and 105 DF, p-value: &lt;2e-16 Notice in each that the independent variables define the rows. In Model2, the estimated slope coefficient for ProfLang is 0.89 with a p-value less than 0.001. This means that on average and net of the number of students tested, a 1-percentage-point increase in language proficiency is associated with a 0.89-percentage-point increase in math proficiency. The association is statistically significant (\\(p&lt;0.001\\)). We might also note that the variables in the model account for almost 90% of observed variation in math proficiency across DC Public Schools (\\(Adj~R^2=0.83\\)). "],["scatter-with-linear-fit.html", "7.3 Scatter with linear fit", " 7.3 Scatter with linear fit We use a scatter plot with linear fit to visualize the bivariate (unconditional) linear associations. First create the scatter with plot() and then overlay the regression line from stored estimates using abline(). Be sure to run these lines together or in succession: plot(ProfMath ~ ProfLang, dcps) # basic scatter abline(Model1) # Add stored linear estimate "],["logistic-regression.html", "7.4 Logistic regression", " 7.4 Logistic regression With a binary outcome measure, logistic regression is generally more appropriate than linear (OLS) regression. Use the glm() function to estimate a generalized model, and specify the model family as binomial within the arguments. # create binary measure of &quot;above average math proficiency&quot; dcps = dcps %&gt;% mutate(AboveAvgMath = if_else(ProfMath &gt; mean(ProfMath),1,0)) Model3 = glm( AboveAvgMath ~ ProfLang + NumTested, # specify model family = &#39;binomial&#39;, # logistic estimation data = dcps ) To view the coefficient estimates and evaluate hypotheses, again apply the summary() function to the model object. # View estimates summary(Model3) ## ## Call: ## glm(formula = AboveAvgMath ~ ProfLang + NumTested, family = &quot;binomial&quot;, ## data = dcps) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.938 -0.547 -0.351 0.213 2.115 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.22427 0.61253 -5.26 1.4e-07 *** ## ProfLang 0.11366 0.02412 4.71 2.4e-06 *** ## NumTested -0.00239 0.00229 -1.04 0.3 ## --- ## Signif. codes: ## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 144.342 on 107 degrees of freedom ## Residual deviance: 77.127 on 105 degrees of freedom ## AIC: 83.13 ## ## Number of Fisher Scoring iterations: 6 # Odds ratios exp(coef(Model3)) ## (Intercept) ProfLang NumTested ## 0.03978 1.12037 0.99761 The results indicate that a percentage-point increase in a schools language proficiency is expected to raise the odds of being above average in math by 12%, conditional on the number of students tested. Again, the increase is significant (\\(p &lt; 0.001\\)). "],["making-regression-tables.html", "7.5 Making regression tables", " 7.5 Making regression tables Use the stargazer() function to transform messy R regression estimates into professional and exportable regression tables. Be sure you have installed and loaded the stargazer package. Then simply specify the model estimates to include. library(stargazer) stargazer( Model1, Model2, # stored estimates to include in the table type = &#39;text&#39;, keep.stat = &#39;n&#39; # add #obs from each model ) ## ## ========================================= ## Dependent variable: ## ---------------------------- ## ProfMath ## (1) (2) ## ----------------------------------------- ## ProfLang 0.876*** 0.894*** ## (0.039) (0.041) ## ## NumTested -0.010 ## (0.007) ## ## Constant 0.910 2.211 ## (1.505) (1.715) ## ## ----------------------------------------- ## Observations 108 108 ## ========================================= ## Note: *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01 You can copy and paste these into a program like Excel or Word, and have a nice table with only a few edits. "],["doing-more-with-data-frames.html", "Chapter 8 Doing more with data frames", " Chapter 8 Doing more with data frames Very few data sets come ready made for analysis. Even in our introductory course, there are times when you will need to limit your analysis to certain observations, recode a variable, and more. This chapter covers a few basics of data munging. Note that you will need the film (\"biopics.xls\") and dcps (\"DCPS testing.RData\") data sets to replicate the commands. "],["filtersubset-data.html", "8.1 Filter/subset data", " 8.1 Filter/subset data It is often necessary to limit your analysis to some subset of cases. Use the filter() command to specify the criteria by which to select cases. film = film %&gt;% filter(SubjectSex == &#39;Female&#39;) # criteria for keeping cases head(film) ## # A tibble: 6 x 10 ## Title Release NumSubjects SubjectName SubjectType ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Big ~ 2014 1 Margaret K~ Artist ## 2 Test~ 2014 1 Vera Britt~ Other ## 3 The ~ 2014 1 Brittany M~ Actress ## 4 Wild 2014 1 Cheryl Str~ Other ## 5 Diana 2013 1 Princess D~ Other ## 6 Love~ 2013 1 Linda Love~ Actress ## # ... with 5 more variables: SubjectRace &lt;chr&gt;, ## # PersonOfColor &lt;dbl&gt;, SubjectSex &lt;chr&gt;, ## # LeadActor &lt;chr&gt;, Period &lt;chr&gt; The conditions inside filter() identify the cases, or rows, to keep (i.e. youre selecting only those rows that satisfy the given conditions). This can be based on any number of conditions. Note that a double equals sign == is used to check a logical condition. "],["selecting-your-variables.html", "8.2 Selecting your variables", " 8.2 Selecting your variables A dataframe with loads of variables can be unwieldy. Use the select() function to isolate the variables you need for your analysis. Study1 = film %&gt;% select(Title,Release,SubjectSex) head(Study1) ## # A tibble: 6 x 3 ## Title Release SubjectSex ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Big Eyes 2014 Female ## 2 Testament of Youth 2014 Female ## 3 The Brittany Murphy Story 2014 Female ## 4 Wild 2014 Female ## 5 Diana 2013 Female ## 6 Lovelace 2013 Female "],["create-new-variables.html", "8.3 Create new variables", " 8.3 Create new variables The mutate() function creates new variables (or columns) in a data frame. By assigning the same object name to the result, the new variables become part of the object. dcps = dcps %&gt;% mutate( LastEdit = &#39;2021&#39;, # character variable with same value in each ProfLangProp = ProfLang/100, # convert to proportion ) dcps %&gt;% select(2,5,8:9) %&gt;% head() ## # A tibble: 6 x 4 ## SchName ProfLang AboveAvgMath LastEdit ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Aiton Elementary Scho~ 5.56 0 2021 ## 2 Amidon-Bowen Elementa~ 16.3 0 2021 ## 3 Anacostia High School 4.48 0 2021 ## 4 Ballou High School 2.78 0 2021 ## 5 Bancroft Elementary S~ 34.3 1 2021 ## 6 Barnard Elementary Sc~ 38.4 1 2021 In addition to transformations that apply the same function to every case, you can create variables that treat cases on an individual basis. Consider the if_else() option. This will specify a logical test to apply to each case, and specify replacement values for those cases that evaluate as true and those cases that evaluate as false. The syntax is: if_else(criteria,value.if.true,value.if.false). dcps = dcps %&gt;% mutate( AbvMedMath = if_else( ProfMath &gt; median(ProfMath), # condition to evaluate 1, # output if condition is TRUE 0 # output if FALSE ) ) dcps %&gt;% select(SchCode,ProfMath,AbvMedMath) %&gt;% head() ## # A tibble: 6 x 3 ## SchCode ProfMath AbvMedMath ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 202 15.3 0 ## 2 203 10.1 0 ## 3 450 1.43 0 ## 4 452 0.498 0 ## 5 204 39.9 1 ## 6 205 39.7 1 "],["appending-and-merging-data.html", "8.4 Appending and merging data", " 8.4 Appending and merging data It is often useful to combine data from different sources. This may take the form of appending (adding additional cases with information on the same variables) or merging (adding additional variables that describe the same cases). 8.4.1 Appending new cases To append new cases to your data frame, use bind_rows(OldData,NewData). Note that the variable names need to match exactly across data frames, but the variable order does not matter. # old data myData = tribble( ~District, ~Students, 115, 985, 116, 1132 ) # new data to add new = tribble( ~District, ~Students, 117, 419, 118, 633 ) # Append new to old myData = bind_rows(myData,new) myData ## # A tibble: 4 x 2 ## District Students ## &lt;dbl&gt; &lt;dbl&gt; ## 1 115 985 ## 2 116 1132 ## 3 117 419 ## 4 118 633 8.4.2 Merging To merge data frames (add new variables for existing cases), use left_join(OldData,NewData). In order to link rows in one data frame to rows in another, it is critical that the data sets contain a common identifier, with the same variable name and same values. Building on the example above # new variables newvars = tribble( ~District,~Teachers, 115, 43, 116, 71, 118, 55 ) # join new to old myData = left_join(myData,newvars) ## Joining, by = &quot;District&quot; myData ## # A tibble: 4 x 3 ## District Students Teachers ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 115 985 43 ## 2 116 1132 71 ## 3 117 419 NA ## 4 118 633 55 "],["basic-visualization.html", "Chapter 9 Basic visualization", " Chapter 9 Basic visualization Note that you will need the dcps data (\"DCPS testing.RData\") to replicate the commands. "],["graphing-in-base-r.html", "9.1 Graphing in base R", " 9.1 Graphing in base R Data visualization is a notable strength of R, and its native (base) capabilities allow you to create high quality, straightforward graphs. 9.1.1 Describe one variable Summarizing briefly what we presented in prior chapters, presenting data on a single variable is primarily a matter of understanding what type of measure you have. Using the dcps data: # Histogram (numeric X) hist(dcps$NumTested) # Boxplot (numeric X) boxplot(dcps$ProfMath, horizontal = TRUE) # Bar plot (nominal X) # 1. relative frequency table tab = dcps %&gt;% count(SchType) %&gt;% mutate(Percent = 100 * n/sum(n)) # 2. barplot from table barplot(Percent ~ SchType, data = tab) 9.1.2 Visualizing relationships For visualizing relationships between variables: # Group comparison (numeric X, nominal Y) boxplot(NumTested ~ SchType, data = dcps) # Scatter plot (numeric X, numeric Y) plot(ProfLang ~ SchType, data = dcps) # Scatter w/OLS fit (numeric X, numeric Y) # 1. store OLS estimates est = lm(ProfLang ~ ProfMath, data = dcps) # 2. plot plot(ProfLang ~ ProfMath, data = dcps) # scatter abline(est) # add linear fit "],["professional-formatting.html", "9.2 Professional formatting", " 9.2 Professional formatting Formatting is what differentiates an exploratory graph from one you would present to others. The options for formatting an R graphic are almost limitless. However, of special importance are the descriptive text (e.g. titles), axis scales, and the graphical parameters (e.g. color and shape of the points). I suggest the Quick-R Advanced Graphs page for more details and for more advanced examples. 9.2.1 Titles and labels Within the different plotting functions, you can specify the main title (main =), axis labels (e.g. xlab =), and more. Choose simple, descriptive labels and titles. hist(dcps$ProfLang, main = &quot;Language Proficiency, DCPS 2018&quot;, xlab = &#39;Grade-level proficient (% tested)&#39;, ylab = &#39;Frequency&#39;) 9.2.2 Axis options Sometimes the axis scales that R chooses dont make sense or fail to communicate effectively. In these cases, we want to format the endpoints, or limits, of each axis scale. You do this using xlim and ylim, which allow you to specify a custom minimum and maximum value on each axis (e.g. xlim = c(min,max)). Note that you must provide both using the appropriate syntax. plot(ProfLang ~ NumTested, data = dcps, xlim = c(0,1500), ylim = c(0,100)) # boundaries on X and Y 9.2.3 Graphical parameters Basic R graphs are clean and sparse; these are important advantages. However, we may want to spice things up beyond the simple black and white. This is especially true in graphs with multiple components (e.g. a scatter plot with linear fit) where color/shape contrast is important to differentiate the elements. See below examples of changing fill color (col), border color (border), point shape (pch), line type (lty), and line width (lwd). # Histogram (or boxplot) hist(dcps$ProfMath, col = &#39;deeppink4&#39;, # fill color border = &#39;gray25&#39;) # broder color # Scatter plots with fit plot(ProfMath ~ ProfLang, data = dcps, pch = 24, # shape of the point col = &#39;red&#39;) # point color abline(lm(ProfMath ~ ProfLang, data = dcps), col = &#39;cornflowerblue&#39;, lty = 4, # line type (1-6) lwd = 3) # line width (3=triple width) "],["exportingsaving-graphs.html", "9.3 Exporting/saving graphs", " 9.3 Exporting/saving graphs Once you have a formatted graph, its time to export it. Find the Export button in the plot window and choose Save as Image (left-hand panel of the figure below). This opens the window shown in the right-hand panel. Here you want to select an appropriate format (typically .jpeg), name, and size. Size is crucial, and the target is the smallest possible without cutting out text. A size of 450x400 pixels is a pretty safe bet for most of what we do in this course. FIGURE 9.1: Fortmat and export graphs "]]
